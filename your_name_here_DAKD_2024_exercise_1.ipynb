{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ebFJO6fm_kpx"
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <h1><center> DAKD 2024 EXERCISE 1: DATA UNDERSTANDING  </center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gxF0BYhu_kpz"
   },
   "source": [
    "This exercise relates to the _data understanding_ and  _data preparation_ stages of the Crisp Data Mining (CRISP-DM) model presented on the course. The questions at this stage of a data-analysis project are for example:\n",
    "\n",
    "- Is the data quality sufficient?\n",
    "- How can we check the data for problems?\n",
    "- How can we clean the data?\n",
    "- How is the data best transformed for modeling?\n",
    "\n",
    "It may be tempting to just run a model on data without checking it. However, not doing basic checks can ruin your whole analysis and make your results invalid as well as mislead you in further analyses. There is no excuse for not plotting and checking that the data is as we expect and clean. In this exercise we do just that, check the validity of data and familiarize ourselves with a dataset, also discussing preprocessing and multi-dimensional plotting.\n",
    "\n",
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XsFBKSsU_kpz"
   },
   "source": [
    "### <font color = red> *** FILL YOUR INFORMATION BELOW *** </font>\n",
    "(Name) <br>\n",
    "(Student number) <br>\n",
    "(UTU email)  <br>\n",
    "(Date)  <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W3jIT0S_3BPb"
   },
   "source": [
    "#### General Guidance for Exercises\n",
    "\n",
    "- **Complete all tasks**: Make sure to answer all questions, even if you cannot get your script to fully work.\n",
    "- **Code clarity**: Write clear and readable code. Include comments to explain what your code does.\n",
    "- **Effective visualizations**: Ensure all plots have labeled axes, legends, and captions. Your visualizations should clearly represent the underlying data.\n",
    "- **Notebook organization**: You can add more code or markdown cells to improve the structure of your notebook as long as it maintains a logical flow.\n",
    "- **Submission**: Submit both the `.ipynb` and `.html` or `.pdf` versions of your notebook. Before finalizing your notebook, use the \"Restart & Run All\" feature to ensure it runs correctly.\n",
    "\n",
    "#### Grading Criteria\n",
    "- The grading scale is **Fail/Pass/Pass with honors (+1)**.\n",
    "  - To **pass**, you must complete the required parts <span style=\"color:red\">[1-7]</span>.\n",
    "  - To achieve **Pass with honors**, complete the bonus exercises.\n",
    "\n",
    "#### Technical Issues\n",
    "- **Initial troubleshooting**: If you encounter problems, start with an online search to find solutions, but do not simply copy and paste code. Understand any code you use and integrate it appropriately.\n",
    "- **External sources**: Cite all external sources used, whether for code or explanations.\n",
    "- **Help resources**: If problems persist, ask for help in the course discussion forum, at exercise sessions, or via email to the course assistants. </span>.\n",
    "\n",
    "#### Use of AI and Large Language Models\n",
    "- We **do not encourage** the use of AI tools like ChatGPT. If you use them, critically evaluate their outputs.\n",
    "  - **Documentation**: Describe how you used the AI tools in your work, including your input and how the output was beneficial.\n",
    "\n",
    "#### Time Management\n",
    "- **Avoid last-minute work**: Do not leave your work until the last moment. No feedback will be available during weekends.\n",
    "\n",
    "#### Additional Notes\n",
    "- You can find the specific deadlines and session times for each assignment on the Moodle course page.\n",
    "- Ensure all your answers are **concise**—typically a few sentences per question.\n",
    "- Your `.ipynb` notebook is expected to be **run to completion**, meaning it should execute without errors when all cells are run in sequence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2I2WLapM3BPc"
   },
   "source": [
    "### <font color = red> Packages needed for this exercise: </font>\n",
    "- The exercise can be done without importing any extra packages, but you can import new ones but bear in mind that if you are importing many new packages, you may be complicating your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kNsRA1WF3BPc"
   },
   "outputs": [],
   "source": [
    "# --- Libraries with a short description ---\n",
    "import pandas as pd # for data manipulation\n",
    "import matplotlib.pyplot as plt # for plotting\n",
    "import numpy as np #for numeric calculations and making simulated data.\n",
    "import seaborn as sns # for plotting, an extension on matplotlib\n",
    "\n",
    "# - sklearn has many data analysis utility functions like scaling as well as a large variety of modeling tools.\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# This forces plots to be shown inline in the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o3M5VL93_kp0"
   },
   "source": [
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <h1><center> PLOTTING TUTORIAL </center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gbz5Zwg__kp1"
   },
   "source": [
    "This small explanation of the matplotlib package aims to avoid confusion and help you avoid common mistakes and frustration. Matplotlib is an object-oriented plotting package with the benefit of giving the user a lot of control. The downside is that it can be confusing to new users. **If you are having problems with the plotting exercises, return to this tutorial as it explains the needed concepts to do the exercises!**\n",
    "\n",
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8gy1EQA4_kp1"
   },
   "source": [
    "###  Figure and axes\n",
    "\n",
    "\n",
    "All plots in matplotlib are structured with the **<font color = dimgrey> figure </font>** and **<font color = blue> axes </font>** objects.\n",
    "\n",
    "- The **<font color = dimgrey> figure </font>** object is a container for all plotting elements (in other words, everything we see).  \n",
    "- A figure can have many **<font color = blue> axes </font>**. They are the objects you plot on to. The axes can be anywhere inside the figure and can even overlap. Position of axes is defined relative to the figure.\n",
    "\n",
    "The **<font color = blue> axes </font>** objects have the methods you will use to define most of your plots. For example axes.hist() is used to draw a histogram and axes.set_title() to give one axes a title. The name of the object can be a bit confusing as it does not refer to the axes in the way \"x-axis\" does but to the container of a single plot.\n",
    "\n",
    "\n",
    "--------------\n",
    "     \n",
    "- Below is an example that illustrates how **<font color = dimgrey> figures </font>**and **<font color = blue> axes </font>** work together in matplotlib. The comments explain what is done in every row of code. <font color = green> You are encouraged to play around with it, but its not required in terms of the exercise </font>. Below, we will create all figures and axes separately, but later on we will use a quicker way to do so.\n",
    "\n",
    " This is not yet a part of the exercises themselves and you do not need to change anything !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Lets make some example data ---\n",
    "x_example_data = np.linspace(0,5,10) # Generate 10 evenly spaced numbers between 0 and 5 for x data\n",
    "y_example_data = x_example_data**2   # Square the x data to create the corresponding y data\n",
    "\n",
    "### ---- Create a Figure ----\n",
    "example_figure = plt.figure(figsize=(5, 5))  # You give the size of the figure as a tuple of inches\n",
    "\n",
    "### ---- Create Outer Axes ----\n",
    "'''\n",
    "Create axes inside the figure. \"e.g example_figure.add_axes(...)\"  The list [0.1, 0.1, 0.9, 0.9] means :\n",
    "  - The left side of the axes is 10% from the left of the figure\n",
    "  - The bottom of the axes is 10% from the bottom of the figure\n",
    "  - The axes take up 90% of the figure’s width and height\n",
    "'''\n",
    "example_axes_outer = example_figure.add_axes([0.1, 0.1, 0.9, 0.9]) \n",
    "\n",
    "### Set labels and titles for the outer axes ###\n",
    "example_axes_outer.set_xlabel(\"This is how you set an x-axis label to an axes\")\n",
    "example_axes_outer.set_ylabel(\"The y-label of an axes is set like this\")\n",
    "example_axes_outer.set_title(\"We learned how to give an axes a title!\")\n",
    "\n",
    "### ---- Create Inner Axes ----\n",
    "example_axes_inner = example_figure.add_axes([0.6, 0.45, 0.2, 0.2]) # Inner axes defined similarly [left, bottom, width, height]\n",
    "example_axes_inner.set_title(\"This inner axes has a title too\")\n",
    "\n",
    "### ---- Plot Data and Customize ----\n",
    "example_axes_inner.scatter(x_example_data, y_example_data)  # Scatter plot on inner axes\n",
    "\n",
    "# you can add multiple things such as (lines) can be plotted on same outer axis.\n",
    "example_axes_outer.plot(x_example_data**4, y_example_data**2)\n",
    "example_axes_outer.plot(x_example_data**7, y_example_data**2)\n",
    "\n",
    "### ---- Add Text Annotation ----\n",
    "# If you want to add other objects, you add them to axes too, like text\n",
    "# Now you specify the location relative to the parent axes\n",
    "example_axes_inner.text(3, 6, \"This is a text object relative to the inner axes\")  # Text relative to the inner axes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dnxKiFY__kp2"
   },
   "source": [
    "### Subplots: Creating Multiple Axes in a Grid\n",
    "\n",
    "A common way to start plotting in Matplotlib is to use the `plt.subplots()` function. This function automatically creates a figure and a specified number of axes (subplots) arranged in a grid, linking them to the figure. Even when creating just one subplot, `plt.subplots()` is often used as it offers flexibility and ease of management.\n",
    "\n",
    "The most important arguments for `plt.subplots()` are:\n",
    "\n",
    "- **nrows**: The number of rows of subplots in the grid.\n",
    "- **ncols**: The number of columns of subplots in the grid.\n",
    "- **figsize**: A tuple like `(6, 4)` that sets the figure size in inches. The first value is the width, and the second is the height.\n",
    "- **sharex**: If `True`, all subplots share the same x-axis scale and ticks.\n",
    "- **sharey**: If `True`, all subplots share the same y-axis scale and ticks.\n",
    "\n",
    "#### Example:\n",
    "\n",
    "Below is an example of how to create subplots. It includes a loop to fill the subplots using the `enumerate()` function, which provides an index that can be used to access individual subplot axes. This is a useful pattern when plotting multiple subplots programmatically.\n",
    "\n",
    "The function `plt.tight_layout()` is also handy for arranging subplots. It automatically adjusts the positions of the axes to ensure they don't overlap, making the figure look cleaner and more readable.It should be called after the plot is finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dMv8JToS_kp2"
   },
   "outputs": [],
   "source": [
    "# ----- Create some random data for the example -----\n",
    "# We generate 3 sets of continuous numeric features and 3 sets of binary features\n",
    "\n",
    "# Generate random continuous data (3 arrays, each with 10 samples of 2 numeric features)\n",
    "numeric_datas = [np.random.rand(10, 2) for _ in range(3)]  # 3 arrays of 10x2 random floats between 0 and 1\n",
    "\n",
    "# Generate binary data (3 arrays, each counting occurrences of 0s and 1s from random binary samples)\n",
    "# np.random.randint creates random integers (0 or 1), np.unique counts them\n",
    "binary_datas = [\n",
    "    np.unique(np.random.randint(0, 2, size=10), return_counts=True)[1] \n",
    "    for _ in range(3)\n",
    "]  # 3 arrays of counts of 0s and 1s (binary features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 512
    },
    "id": "E9F1xhXN_kp2",
    "outputId": "939d4014-c1f9-445d-e777-31977eafb9e0"
   },
   "outputs": [],
   "source": [
    "# Create figure with six axes in a 2*3 grid and set up titles --------------------------------------------------------\n",
    "fig, axes = plt.subplots(2,3, figsize = (10,5)) # now axes have indexes like axes[i, j]\n",
    "numeric_plot_titles = ['scatter_plot_1', 'a second plot', 'yet a third plot' ]#some titles for the different axes\n",
    "binary_plot_titles = ['coin_tosses1', 'tossing again', 'still tossing' ]#some titles for the different axes\n",
    "\n",
    "\n",
    "# Enumerate the index into the axes, fill the first 3 columns of first row with scatterplots of numeric_datas --------\n",
    "i = 0 # for indexing to the row of the axes [**i**, j]\n",
    "for j, numeric_data in enumerate(numeric_datas): # j = [0,1, ... n_datasets] for filling the columns, i stays constant as its the row\n",
    "    axes[i, j].scatter(x = numeric_data[:, 0], y = numeric_data[:, 1]) #plots are called on the axes\n",
    "    axes[i, j].set_title(numeric_plot_titles[j]) #set a title for each axes\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "# Plot the binary data -----------------------------------------------------------------------------------------------\n",
    "i = 1 # second row\n",
    "for j, binary_data in enumerate(binary_datas): # j = [0,1, ... n_datasets] for filling the columns, i stays constant as its the row\n",
    "    axes[i, j].bar(x = [\"0\",\"1\"], height = binary_data) #make a barplot\n",
    "    axes[i, j].set_title(binary_plot_titles[j]) #set a title for each axes\n",
    "    axes[i, j].set_ylim((0,10)) # set the yaxis limits, set_xlim works the same way.\n",
    "\n",
    "fig.suptitle(\"fig.suptitle gives the figure a title and axes.set_title the axes\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZLR7YeuY_kp3"
   },
   "source": [
    "#### <span style=\"color: maroon;\">Seaborn and Matplotlib (new)</span>\n",
    "\n",
    "Seaborn is a popular plotting library built on top of Matplotlib. It was designed to make creating statistical plots easier, more intuitive, and visually appealing with minimal effort. Seaborn is especially known for its default color palettes and built-in support for complex visualizations, making it faster to use compared to plain Matplotlib.\n",
    "\n",
    "When working with Seaborn, it’s important to understand that there are two kinds of plotting functions:\n",
    "- **Figure-level plots**: These functions manage the entire figure themselves (including creating the figure and subplots) and cannot be easily integrated into custom subplot grids. Examples include `sns.catplot()` and `sns.lmplot()`.\n",
    "- **Axes-level plots**: These functions work on individual Matplotlib axes and can be combined with Matplotlib's `subplots()` to create complex, multi-plot figures. Examples include `sns.scatterplot()` and `sns.histplot()`.\n",
    "\n",
    "For axes-level plots, you can pass a Matplotlib axes object to the Seaborn plotting function to specify where the plot should appear. This allows you to mix Matplotlib and Seaborn plots in the same figure. Below is an example of how to use Seaborn to plot on a specific set of axes.\n",
    "\n",
    "If you'd like to dive deeper into the different types of Seaborn functions and when to use them, you can find more information in the [Seaborn function overview](https://seaborn.pydata.org/tutorial/function_overview.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "id": "L7xXByP1_kp3",
    "outputId": "da60578a-9c4b-476e-b060-bdb627bc818b"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2)\n",
    "\n",
    "# make some data\n",
    "random_data_a = np.random.rand(30)\n",
    "random_data_b = np.random.rand(100)\n",
    "\n",
    "# print the data we are plotting\n",
    "sns.histplot(data = random_data_a, ax = axes[0]) # we make a seaborn plot and put it into one of the axes we created\n",
    "sns.histplot(data =  random_data_b, ax = axes[1]) # we make a seaborn plot and put it into one of the axes we created"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xKfVHL9__kp3"
   },
   "source": [
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <h1><center> START OF EXERCISES </center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8AZs1Rdr3BPd"
   },
   "source": [
    "##  <font color = dimgrey> 1. Introduction to the dataset </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Y4dstDz3BPe"
   },
   "source": [
    "The dataset in this exercice contains comprehensive health information from  hospital patients with and without cardiovascular disease. The target variable \"cardio,\" reflects the presence or absence of the disease, which is characterized by a buildup of fatty deposits inside the arteries (blood vessels) of the heart.\n",
    "\n",
    " -------\n",
    "As is often the case with data analysis projects, the features/variables have been retrieved from different sources:\n",
    "- doctors notes (texts)\n",
    "- examination variables that have come from a database containing lab results or taken during a doctors examination\n",
    "- self reported variables\n",
    "\n",
    "--------------\n",
    "The exercise data has the following columns/attributes:\n",
    "\n",
    "| Feature | Type | Explanation |\n",
    "| :- | :- | :-\n",
    "| age | numeric | The age of the patient in days\n",
    "| gender | binary | Male/Female\n",
    "| body_mass | numeric | Patient's measured weight, in kilograms (kg).\n",
    "| height | numeric | Patient's measured height, in centimeters (cm).\n",
    "| blood_pressure_high | numeric | Measured Systolic blood pressure\n",
    "| blood_pressure_low | numeric | Measured Diastolic blood pressure\n",
    "| smoke | binary | A subjective feature based on asking the patient whether or not he/she smokes\n",
    "| active | binary |  A subjective feature based on asking the patient whether or not he/she exercises regularly\n",
    "| serum_lipid_level | categorical | Serum lipid / Cholesterol associated risk information evaluated by a doctor\n",
    "|family_history| binary | Indicator for the presence of family history of cardiovascular disease based on medical records of patients\n",
    "| cardio | binary | Whether or not the patient has been diagnosed with cardiac disease."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jMatXBHE3BPh"
   },
   "source": [
    "-----------\n",
    "#### ***Reading data***\n",
    "\n",
    "It is good practice to read the features in using their correct types instead of fixing them later. Below, there is ready-made code for you to read in the data, using the data types and column names listed in the above table. Don't change the name of the variable, _data_. It is important in later exercises (for example in ex. 5e) that this is the name of the variable. <font color = red> If you have the dataset in the same folder as this notebook, the path already given to you should work. </font>\n",
    "\n",
    "---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mMz_5o3t_kp3"
   },
   "outputs": [],
   "source": [
    " # --- READ IN DATA (no need to change) --------\n",
    "data_path = \"CardioCare_ex1.csv\" #if you just give the name of the file it will look for the data in the same folder as your script\n",
    "data = pd.read_csv(data_path, dtype = {'age': 'int', 'height': 'int', 'body_mass':'int', 'blood_pressure_low':'int', 'blood_pressure_high':'int', 'gender': 'boolean', 'smoke': 'boolean',\n",
    "       'active':'boolean', 'cardio':'boolean', 'serum_lipid_level':'category', 'family_history':'boolean'}) #the main data you use in this exercise should have this variable name, so that code given for you further on will run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ru2t9oKU_kp4"
   },
   "source": [
    "---------\n",
    "***Exercise 1 a)***\n",
    "1. First, print out the first five rows of the data.\n",
    "\n",
    "2. Then, save the feature names to lists by their types:\n",
    "   - Create three lists named **numeric_features**, **binary_features**, and **categorical_features**. \n",
    "   - These lists should contain the **names** of the features based on their types:\n",
    "     - Numeric features (e.g., `age`, `body_mass`, etc.)\n",
    "     - Binary features (also known as boolean, e.g., `gender`, `smoke`, `cardio`, etc.)\n",
    "     - Categorical features (e.g., `serum_lipid_level`)\n",
    "\n",
    "---\n",
    "\n",
    "#### Important Notes:\n",
    "\n",
    "When working with DataFrames, it is often useful to organize column names into lists. This practice simplifies data manipulation and analysis. Once the feature names are organized, you can easily select, filter, or apply operations to specific groups of features. This also helps to avoid typing errors and reduces repetition.\n",
    "\n",
    "For example, once you create your list of numeric features, you can select all columns containing numeric data with the following command:\n",
    "\n",
    "```python\n",
    "data[numeric_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WAgzn52D_kp4"
   },
   "outputs": [],
   "source": [
    "# --- Your code here for 1 a) ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k541Oaic_kp4"
   },
   "source": [
    "-----\n",
    "In many data analysis projects, the data is often not collected specifically for analysis purposes. Instead, it may come from various sources or be collected for entirely different reasons. As a result, the data might not be well-formatted and could contain errors or inconsistencies. \n",
    "\n",
    "It might be tempting to immediately apply a model to the data \"as is,\" but it is crucial to first **check the data for quality issues**. Ignoring potential data issues can lead to misleading conclusions, undermining the entire analysis. \n",
    "\n",
    "### Why Data Quality Checks Matter:\n",
    "\n",
    "One standard routine to ensure data quality is:\n",
    "1. **Calculate descriptive statistics** for each feature. This gives an overview of the distribution, range, and possible anomalies.\n",
    "2. **Visualize the features** to check whether the values are realistic and within expected ranges.\n",
    "\n",
    "This step helps identify outliers, incorrect data entries, or formatting issues, ensuring that your analysis is based on clean and reliable data.\n",
    "\n",
    "---\n",
    "\n",
    "### Descriptive Statistics and Data Types\n",
    "\n",
    "It's important to note that certain descriptive statistics might not be meaningful for specific types of features. For instance, calculating the \"mean\" for binary or categorical features may not offer valuable insight. In **pandas** (as in many other data analysis packages), some functions behave differently depending on the data type of the column.\n",
    "\n",
    "In the following exercises, we will explore:\n",
    "- **Descriptive statistics** for the dataset.\n",
    "- How the results and behavior of descriptive functions can vary based on the data type (e.g., numeric vs. categorical features).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AIajREt-_kp4"
   },
   "source": [
    "----------\n",
    "***Exercise 2 a)***  Print out the data types of your dataset below.\n",
    "\n",
    "_Perhaps the most common data types in pandas (see https://pandas.pydata.org/docs/user_guide/basics.html#basics-dtypes) are **float**, **int**, **bool** and **category**._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A5fCeou0_kp4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- 2 a) Print the feature types of your dataset --- #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X2SoeW_t_kp5"
   },
   "source": [
    "--------\n",
    "***Exercise 2 b)*** Use the **DataFrame.describe() method** in the cell below on your data.   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6UOMFm6-_kp5"
   },
   "outputs": [],
   "source": [
    "# --- Your code for 2 b) --- #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ft8fMH3w_kp5"
   },
   "source": [
    "--------\n",
    "***Exercise 2 c)*** Did you get all of the features statistics or not? What do you think happened?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lpzzUTFml0Mz"
   },
   "source": [
    "<font color=\"green\">Your answer for 2 c)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LHfWwFco_kp5"
   },
   "source": [
    "----------\n",
    "***Exercise 2 d)*** Calculate descriptives for the binary (boolean) features and the categorical feature <br>\n",
    "\n",
    "_tip: in python, same type data structures can in many cases be concatenated using the + operator. If youre using the lists of names you created to subset, you can concatenate the two lists of feature names and use the resulting list to help you subset the dataframe_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lnL4C_l7_kp5"
   },
   "outputs": [],
   "source": [
    "# 2 d) Your code here #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FeBe_Ig7_kp6"
   },
   "source": [
    "Now, we will explore **what happens if the data is read using the default settings** (i.e., without specifying the data types for the features). In this case, we are **not providing information about the data types (dtypes)** to `pd.read_csv`, meaning no additional arguments are passed when loading the data.\n",
    "\n",
    "Run the cell below (you don't need to modify the code) and observe the output of the data that has been incorrectly read due to missing dtype information. Then, compare this output with the data you loaded earlier using the correct dtypes, and check the descriptive statistics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jj4sId-Y_kp6"
   },
   "outputs": [],
   "source": [
    "# read in the dataset with no arguments\n",
    "wrongly_read_data = pd.read_csv(data_path)\n",
    "\n",
    "# calculate descriptives for the data that was wrongly read in.\n",
    "wrongly_read_data.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hGsnQYT1_kp6"
   },
   "source": [
    "\n",
    "***Exercise 2 e)*** \n",
    "Based on the output above, can you identify what went wrong with the data presentation? Why was it important to correctly define the data types when loading the dataset?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qx72UtvZ_kp6"
   },
   "source": [
    "<font color=\"green\">Your answer for 2 e)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dhd3oOoe_kp6"
   },
   "source": [
    "-----------------------\n",
    "## 3. Plotting numeric features\n",
    "Descriptives don't really give a full or intuitive picture of the distribution of features. Next, we will make use of different plots to check the data quality.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4a4ipQ0Q_kqD"
   },
   "source": [
    "----------\n",
    "***Exercise 3 a)*** Plot histograms for the **numeric features** to visually inspect their distributions. (Refer to the tutorial if you need assistance with plotting.)\n",
    "\n",
    "\n",
    "_tip: When using `plt.subplots()`, if you provide only one argument for the grid size (e.g., `plt.subplots(3)`), it will create a **one-dimensional grid**. You can then index this grid with a single index, making it easier to loop through and assign plots to each subplot.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BqsefPHV_kqE"
   },
   "outputs": [],
   "source": [
    "# --- Your code for 3 a) here --- #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "grcF8v9K_kqE"
   },
   "source": [
    "_______\n",
    "## 4. Plotting binary and categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7MUi2Kfi_kqE"
   },
   "source": [
    "***Exercise 4 a)*** Plot **barplots** for each of the **non-numeric features** in the dataset. Make sure to **use fractions** instead of the actual frequencies of the categories.\n",
    "\n",
    " Tips:\n",
    "- To create the barplots, refer to the documentation for `axes.bar`.\n",
    "- To obtain the fractions of each category, use the `value_counts()` function with the `normalize` argument set to `True`. This will return the relative frequencies of each category (proportion of each category relative to the total).\n",
    "\n",
    "**Note:** \n",
    "\n",
    "If you imported boolean features as `pandas` dtype `boolean`, you may find it easier to work with plotting libraries like `matplotlib` when these values are represented as numbers (`0` and `1`) instead of `True` and `False`.\n",
    "\n",
    "If you encounter any errors while plotting, you can temporarily convert these boolean values to integers or floats using the `.astype()` method:\n",
    "\n",
    "```python\n",
    "# Example of converting boolean to int:\n",
    "data['..'] = data['..'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pnDjdDE__kqE",
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Your code for 4 a) here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HblwIAWS_kqE"
   },
   "source": [
    "**Exercise 4 b)** After reviewing the barplots above, Do you notice anything (unusual/irrelevant) with one of the features? If so, Let's try fix it.\n",
    "\n",
    "If you have read the dtype of a categorical feature as `pandas` dtype `categorical`, you must also use the `remove_categories()` function to remove any unnecessary category levels.\n",
    "\n",
    "To remove a specific category level, you can use the following example syntax:\n",
    "\n",
    "```python\n",
    "data['feature_name'] = data['feature_name'].cat.remove_categories(\"category name to delete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tTbxzFDf_kqE"
   },
   "source": [
    "<font color=\"green\">Your answer for 4 b)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OxO5PTRf_kqF"
   },
   "outputs": [],
   "source": [
    "### Your code for 4 b) here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XYDja_ze_kqF"
   },
   "source": [
    "-------------\n",
    "\n",
    "## 5. Feature generation and exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mGu2gXLGuBjS"
   },
   "source": [
    "Feature Engineering is a crucial step in the process of preparing data for most data analysis projects. It involves creating new features or modifying existing ones to improve the performance of predictive models. Feature engineering is a combination of domain knowledge, creativity, and data analysis, and it can have a significant impact on the success of a data analysis project.\n",
    "\n",
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y1awz0XauHJ-"
   },
   "source": [
    "**BMI**, or **Body Mass Index**, is a simple numerical measure that is commonly used to assess an individual's body weight in relation to their height. In our use case, BMI can be a useful indicator in the prediction of cardiovascular problems, as it could provide a well-established link between obesity and an increased risk of developing the disease.\n",
    "\n",
    "\\begin{align*}\n",
    "\\text{BMI} & = \\frac{\\text{Body mass (kg)}}{(\\text{height (m)})^2} \\\\\n",
    "\\end{align*}\n",
    "\n",
    "---------------------------------------\n",
    "***Exercise 5 a)*** Generate a new feature called **BMI** using the provided formula that incorporates the **height** and **body_mass** features.\n",
    "\n",
    "\n",
    "_tip: In this dataset, the **height** is recorded in centimeters. Before applying the formula, ensure that you convert the height from centimeters to meters by dividing by 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z8nHH09YuPa1"
   },
   "outputs": [],
   "source": [
    "### Your code for 5 a) here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HYPN0U1ouOoS"
   },
   "source": [
    "***Exercise 5 b)*** Using the previously calculated feature **BMI** generate a new feature named **BMI_category** that categorizes the values into groups, according to the standard BMI categories :\n",
    "\n",
    "- Underweight: BMI less than 18.5\n",
    "- Normal Weight: BMI between 18.5 and 24.9\n",
    "- Overweight: BMI between 25 and 29.9\n",
    "- Obese: BMI of 30 or greater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I5qZQCIHBoZj"
   },
   "outputs": [],
   "source": [
    "### Your code for 5 b) here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AQTdY0_f0q8-"
   },
   "source": [
    "Now that we have our BMI values, it's a good practice to see if we can spot a hidden trend in our data.\n",
    "\n",
    "***Exercise 5 c)*** Create a countplot to visualize the distribution of cardio (target variable) across different BMI categories.\n",
    "Here, countplot refers to a type of bar plot that displays the frequency (count) of observations in each category of a categorical variable, visualizing the distribution of data by showing how many instances fall into each category.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EQ6HPrcN1GL-"
   },
   "outputs": [],
   "source": [
    "### Your code for 5 c) here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GfzWmYty1IzA"
   },
   "source": [
    "***5 d)*** Can you notice any relationship or visible trend?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "soCh_CqSmh9U"
   },
   "source": [
    "<font color=\"green\">Your answer for 5 d)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAZOWk3QxmKk"
   },
   "source": [
    "Below, there is ready-made code for you to appropriatly add the newly created features to the right column type list. You don't need to change anything about the code, just make sure that the names of the added features are as specified earlier (**BMI** and **BMI_category**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mFW3dSpF1wAx"
   },
   "outputs": [],
   "source": [
    "# ---- Add features to column type list (no need to change) --------\n",
    "numeric_features.append(\"BMI\")\n",
    "data['BMI_category'] = data['BMI_category'].astype('category')\n",
    "categorical_features.append(\"BMI_category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OHZehiD-_kqF"
   },
   "source": [
    "-------------\n",
    "\n",
    "## 6. Preprocessing numeric features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QvAxmrP1_kqF"
   },
   "source": [
    "Scaling the data is a crucial step in the preprocessing phase of machine learning, as it can significantly improve algorithm performance. In many cases, if scaling is not applied, it may lead to poor performance. This is particularly true for distance-based algorithms covered in the course, such as PCA, t-SNE, KNN and Kmeans where features with larger values can dominate the distance calculations.\n",
    "\n",
    "---\n",
    "\n",
    "### Common Scaling Techniques:\n",
    "\n",
    "In this exercise, we will explore two commonly used methods for scaling data:\n",
    "\n",
    "1. **Min-Max Scaling to [0, 1]:** \n",
    "   - This technique rescales the feature values to a range between 0 and 1. It is particularly useful when you want to maintain the relationships between the values while fitting the data into a specific range. This method is often used in training neural networks, where matching the input range to the range of activation functions is important.\n",
    "\n",
    "2. **Standardization :**\n",
    "   - standardizing the features to 0 mean and unit variance. Standardizing values is very common in statistics.\n",
    "\n",
    "### Available Functions:\n",
    "\n",
    "To assist you in applying these scaling techniques, the following functions from the `sklearn` library have been imported for your use:\n",
    "\n",
    "- `sklearn.preprocessing.minmax_scale`: For Min-Max Scaling.\n",
    "- `sklearn.preprocessing.scale`: For Standardization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ccSWzwJL_kqF"
   },
   "source": [
    "**6 a)** Min-max numeric attributes to [0,1] and **store the results in a new dataframe called data_min_maxed**. You might have to wrap the data to a dataframe again using pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8LIvkXpA_kqF"
   },
   "outputs": [],
   "source": [
    "# --- Your code for 6 a) here --- #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "miuOrTJE_kqG"
   },
   "source": [
    "**Exercise 6 b)** Standardize the numeric attributes of the dataset to have a mean of 0 and a standard deviation of 1. Store the standardized results in a new DataFrame called `data_standardized`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bVxlvF5j_kqG"
   },
   "outputs": [],
   "source": [
    "# Your code for 6 b here --- #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NhozF3gN_kqG"
   },
   "source": [
    "**Exercise 6 c)** Create two boxplots for the 'age' feature: one using the `data_min_maxed` DataFrame and the other using the `data_standardized` DataFrame. Display the plots side-by-side and provide titles for each plot. See the tutorial in the beginning for help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TpPWGs1B_kqG"
   },
   "outputs": [],
   "source": [
    "# Your code for 6 c) here --- #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uU0nFxLKF1ta"
   },
   "source": [
    "**Execise 6 d)** Describe what you would expect to see in these two boxplots. How would the characteristics of the boxplots differ for min-max scaled data and standardized data?\n",
    "\n",
    "_tip: Consider factors like the location of the mean, and the range of values presented._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0dQjpocfHfdJ"
   },
   "source": [
    "<font color=\"green\">Your answer for 6 d)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tPt3NRl7_kqG"
   },
   "source": [
    "---------\n",
    "\n",
    "Let's compare the effects of these preprocessing methods on a dataset with an outlier. We'll replace the last data point with an outlier (a value significantly different from the rest) and then apply min-max scaling and standardization. Finally, we'll visualize the results to observe how each method handles the outlier. The code to add the value is given for you and you shouldn't change it.\n",
    "\n",
    "--------------------\n",
    "\n",
    "***Exercise 6 e) Do the following:***\n",
    "1. **Use the Provided Data:**\n",
    "   - Start with the given data for the 'age' feature, which includes an outlier. This variable is referred to as `age_w_outlier`. The value of `age_w_outlier` is already set for you, so you don't need to modify it.\n",
    "\n",
    "2. **Create Min-Max Scaled Variable:**\n",
    "   - Use the `sklearn.preprocessing.minmax_scale` function to apply Min-Max scaling to `age_w_outlier`. Store the scaled values in a new variable named `age_w_outlier_minmaxed`.\n",
    "\n",
    "3. **Create Standardized Variable:**\n",
    "   - Use the `sklearn.preprocessing.scale` function to standardize the values of `age_w_outlier`. Store the standardized values in a new variable named `age_w_outlier_standardized`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EmWfO7E4_kqG"
   },
   "outputs": [],
   "source": [
    "### Add an outlier, DONT CHANGE THIS CELL CODE, JUST RUN IT ###\n",
    "data_w_outlier = data.copy() #data should be the name of the variable where you have stored your data!\n",
    "data_w_outlier.loc[data.shape[0] -1 , 'age'] = 150 #change the last value of age to be 150\n",
    "age_w_outlier = data_w_outlier.age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MTm7xCg7_kqG"
   },
   "outputs": [],
   "source": [
    "# --- Your code for 6 e) ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QaP1uVTN_kqH"
   },
   "source": [
    "***Below there is pre-written code for you to plot the different cases. Run it. The code should run if you have named your features appropriately. Run the code.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 887
    },
    "id": "0dOnjd2__kqH",
    "outputId": "e108827d-4124-461d-bfa2-a184d4dee7e2"
   },
   "outputs": [],
   "source": [
    "# Wrap in a dataframe that will have two features - the age feature without the outlier, and the age feature with it, min-maxed.\n",
    "minmaxed_datas = pd.DataFrame({\"minmaxed_age_no_outlier\" : data_min_maxed.age,\n",
    "              \"minmaxed_age_with_outlier\": age_w_outlier_minmaxed })\n",
    "\n",
    "# Wrap in a dataframe that will have two features - the age feature without the outlier, and the age feature with it, standardized.\n",
    "standardized_datas = pd.DataFrame({\"standardized_data_no_outlier\" : data_standardized.age,\n",
    "              \"standardized_data_w_outlier\": age_w_outlier_standardized })\n",
    "\n",
    "axes_minmaxed = minmaxed_datas[['minmaxed_age_no_outlier', 'minmaxed_age_with_outlier']].plot(kind='box', title='Minmax with and without outlier')\n",
    "axes_std = standardized_datas[['standardized_data_no_outlier', 'standardized_data_w_outlier']].plot(kind='box', title='Standardized with and without outlier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "69aVq8Hc_kqH"
   },
   "source": [
    "----------\n",
    "**Exercise 6 f) Look at the output of the above cell and answer the following**:\n",
    "\n",
    "1. Can you notice a difference between the two cases (min-maxed and standardized)?\n",
    "2. Can you say something about the difference of the effect of min-maxing and standardization?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GcYS23iv_kqH"
   },
   "source": [
    "<font color=\"green\">Your answer for 6 f)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hr-4pk06_kqH"
   },
   "source": [
    "---------------\n",
    "## 7. Preprocessing categorical features\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pjc3qw2U_kqH"
   },
   "source": [
    "We can roughly divide categorical variables/features to two types:  ***nominal categorical***  and  ***ordinal categorical*** variables/features. Some cases are clear in terms of which of the two a feature falls into. For example nationality is not an ordered feature, but which grade in school someone is has a natural ordering. **One-hot encoding** was presented in the lectures and will be used in the following exercises with different learning methods.\n",
    "\n",
    "\n",
    "-----\n",
    "***Nominal categorical features need to be encoded***, because not encoding them implies that they have an order. For example, consider a dataset where you would have rows by different countries, encoded randomly with numbers, for ex. Finland = 1, Norway = 2 and so on. For some analyses and methods this would imply that Norway is somehow \"greater\" in value than Finland. For some algorithms, the implication would also be, that some of the countries would be \"closer\" to each other.\n",
    "\n",
    "------\n",
    "***Ordinal categorical features do not necessarily need to be encoded***, but there are cases where it can be wise. One case is that the categories are not even distance from each other, which is the case with the 'serum_lipid_level' feature with the levels 'normal', 'elevated' and 'at risk'. Its not clear that these are equal in distance from each other. When unsure, it may also be better to one-hot encode, and a lot of packages do it for you behind the scenes. Here we decide to one-hot encode.  \n",
    "\n",
    "---------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OsOJtX3T_kqH"
   },
   "source": [
    "***Exercise 7 a)*** Apply One-hot-encode to the `serum_lipid_level` feature and add the resulting one-hot encoded features back to the DataFrame. Give the new features meaningful names. Print the first rows of the resulting dataframe.\n",
    "\n",
    "_tip: pandas has a function for this, google!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Iu5tYvxb_kqI"
   },
   "outputs": [],
   "source": [
    "# --- Your code for 7 a) here ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sSymI4IK_kqI"
   },
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Dp1XqCF_kqI"
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <h1><center> BONUS EXERCISES </center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PryP-CZb_kqI"
   },
   "source": [
    "- Below are the bonus exercises. You can stop here, and get the \"pass\" grade.\n",
    "- By doing both of the bonus exercises below, you can get a \"pass with honors\", which means you will get one point bonus for the exam.\n",
    "\n",
    "The following exercises are more challenging and not as straight-forward and may require some research of your own. However, perfect written answers are not required, but answers that show that you have tried to understand the problems and explain them with your own words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bea2hNxp3BPv"
   },
   "source": [
    "____________\n",
    "##  <font color = dollargreen > 8. BONUS: Dimensionality reduction and plotting with PCA </font>\n",
    "In the lectures, PCA was introduced as a dimensionality reduction technique. Here we will use it to reduce the dimensionality of the numeric features of this dataset and use the resulting compressed view of the dataset to plot it. This means you have to, run PCA  and then project the data you used to fit the PCA to the new space, where the principal components are the axes.\n",
    "____________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VkrITFMU_kqI"
   },
   "source": [
    "-------------\n",
    "**Exercise 8 a)** Do PCA with two components with and without z-score standardization **for the numeric features in the data**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uYrWkN2L_kqI"
   },
   "outputs": [],
   "source": [
    "# --- Your for 8 a) code here --- #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dV_UOAT0_kqJ"
   },
   "source": [
    "-------------\n",
    "\n",
    "\n",
    "**Exercise 8 b) Plot the data, projected on to the PCA space as a scatterplot, the x-axis being one component and y the other. **Add the total explained variance to your plot as an annotation**. See the documentation of the pca method on how to get the explained variance.\n",
    "\n",
    "- _Tip: It may be easier to try the seaborn scatterplot for this one. For help see documentation on how to do annotation (see tutorial). The total explained variance is the sum of both the components explained variance_.\n",
    "\n",
    "- _Tip2_: Depending on how you approach annotating the plot, you might have to cast the feature name to be a string. One nice way to format values in python is the f - formatting string, which allows you to insert expressions inside strings (see example below):\n",
    "\n",
    "\n",
    "\n",
    "------\n",
    "name = Valtteri<br>\n",
    "print(f\"hello_{name}\")\n",
    "\n",
    "---------\n",
    "You can also set the number of wanted decimals for floats<br>\n",
    "For example f'{float_variable:.2f}' would result in 2 decimals making it to the string created\n",
    "\n",
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u34fQiOH_kqJ"
   },
   "outputs": [],
   "source": [
    "# --- Your code for 8 b) --- you can make more cells if you like ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vI0NIHNo_kqK"
   },
   "source": [
    "\n",
    "\n",
    "**Exercise 8 c) Gather information for the next part of the exercise and print out the following things:**\n",
    "- First, the standard deviation of the original data features (not standardized, and with the numeric features only).\n",
    "- Second, the standard deviation of the standardized numeric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UZNGyOR4_kqK"
   },
   "outputs": [],
   "source": [
    "# --- Your code for 8 c) here --- #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1E4OaFlz_kqK"
   },
   "source": [
    "----------\n",
    "**Exercise 8 d) Look at the output above and the explained variance information you added as annotations to the plots. Try to think about the following questions and give a short answer of what you think has happened:**\n",
    "\n",
    "1. Where do you think the difference between the amounts of explained variance might come from?\n",
    "\n",
    "2. Can you say something about why it is important to scale the features for PCA by looking at the evidence youve gathered?\n",
    "\n",
    "__Answer in your own words, here it is not important to get the perfect answer but to try to think and figure out what has happened__\n",
    "\n",
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vGxNldhDoC6e"
   },
   "source": [
    "<font color=\"green\">Your answer for 8 d)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TZp1Hrm2_kqK"
   },
   "source": [
    "------------------\n",
    "\n",
    "## <font color = dollargreen > 9. Bonus: t-SNE and high dimensional data </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Qh5Dqe2_kqK"
   },
   "source": [
    "Another method that can be used to plot high-dimensional data introduced in the lectures was t-distributed Stochastic Neighbor Embedding (t-SNE)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qtDyOtjd_kqL"
   },
   "source": [
    "***Exercise 9 a)*** Run t-SNE for both standardized and non standardized data (as you did with PCA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6QRLnCUx_kqL"
   },
   "outputs": [],
   "source": [
    "# --- Your code for 9 a) here --- #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DDko4dYb_kqL"
   },
   "source": [
    "***Exercise 9 b)*** Plot t-sne, similarly to PCA making the color of the points correspond to the levels of the cardio feature, but having only numerical features as a basis of the T-SNE.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "onFIgIN5_kqL"
   },
   "outputs": [],
   "source": [
    "# --- Code for 9 b) --- #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iLRIon1t_kqL"
   },
   "source": [
    "***Exercise 9 c)***\n",
    "\n",
    "- What do you think might have happened between the two runs of t-SNE on unstandardized and standardized data? Why is it important to standardize before using the algorithm?\n",
    "\n",
    "_Here the aim is to think about this and learn, not come up with a perfect explanation. Googling is encouraged. Think about whether t-sne is a distance based algorithm or not?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i1XW_cb4oY8o"
   },
   "source": [
    "<font color=\"green\">Your answer for 9 c)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SZY8Vbotoac_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "180px",
    "width": "160px"
   },
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
